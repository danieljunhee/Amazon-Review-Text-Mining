{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Review Text Mining\n",
    "### Jun Hee Kim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, our goal is to predict the rating score (an integer out of 1, 2, 3, 4, 5) given only the Amazon review text. In other words, we will try to capture the customer's overall satisfaction about the product from the review text that he/she wrote. We will explore diverse types of preprocessing raw text data into a format that can be provided to machine learning models. More specifically, we will try several bag-of-words models to represent the Amazon review text and examine which type of representation of the text yields the best predictive performance.\n",
    "\n",
    "For the data, we will be using the Amazon reviews on movies and TV ranging from May 1996 to July 2014. Here is the dataset source: http://jmcauley.ucsd.edu/data/amazon/. The original dataset contains information about 1697533 reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the libraries that we will use for our work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "import math\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the dataset, which is originally in json format, as a Pandas dataframe. The original dataset contains the following variables:\n",
    "- \"reviewerID\": ID of the reviewer, e.g. A2SUAM1J3GNN3B\n",
    "- \"asin\": ID of the product, e.g. 0000013714\n",
    "- \"reviewerName\": name of the reviewer\n",
    "- \"helpful\": helpfulness rating of the review, e.g. 2/3\n",
    "- \"reviewText\": text of the review\n",
    "- \"overall\": rating of the product\n",
    "- \"summary\": summary of the review\n",
    "- \"unixReviewTime\": time of the review (unix time)\n",
    "- \"reviewTime\": time of the review (raw)\n",
    "\n",
    "Since our goal is to predict the rating score solely from the review text, we only keep these columns: \"overall\" is for the rating score (an integer out of 1, 2, 3, 4, 5) and \"reviewText\" is for the corresponding review text (string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### The following 5 lines of commented code is for loading the dataset from the original file and saving as a pickle file. #####\n",
    "## Load data from original file\n",
    "#reviews_df = pd.read_json('Movies_and_TV_5.json', \\\n",
    "#                             lines=True).drop(['reviewerID','asin','reviewerName','helpful','summary','unixReviewTime','reviewTime'], \\\n",
    "#                                              axis=1)\n",
    "## Save this Pandas dataframe as a pickle file (so that we don't have to load it again later)\n",
    "#reviews_df.to_pickle('reviews_df.pickle')\n",
    "\n",
    "# Load the dataframe that has been already saved as a pickle file\n",
    "reviews_df = pd.read_pickle('reviews_df.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the following cell, our dataframe has 1697533 datapoints each with 2 variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1697533, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first five rows of the dataframe looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>This is a charming version of the classic Dick...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>It was good but not as emotionally moving as t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Don't get me wrong, Winkler is a wonderful cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Henry Winkler is very good in this twist on th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>This is one of the best Scrooge movies out.  H...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall                                         reviewText\n",
       "0        4  This is a charming version of the classic Dick...\n",
       "1        3  It was good but not as emotionally moving as t...\n",
       "2        3  Don't get me wrong, Winkler is a wonderful cha...\n",
       "3        5  Henry Winkler is very good in this twist on th...\n",
       "4        4  This is one of the best Scrooge movies out.  H..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we perform preprocessing on the 'reviewText' feature. Our first step of preprocessing the text is tokenization. After tokenizing, we remove all tokens that include numbers, remove all punctuations across the tokens, and convert the tokens to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['where', 'is', 'air']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_tokens_with_num(tokens):\n",
    "    \"\"\"\n",
    "    'tokens' is a list of tokens.\n",
    "    Returns a list of tokens where only tokens without numbers are maintained\n",
    "    \"\"\"\n",
    "    return [token for token in tokens if not re.search('\\d', token)]\n",
    "remove_tokens_with_num(['where', 'is', '3es', 'air', 'd2oy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I  am a person How are you hey'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punc_in_str(str_):\n",
    "        \"\"\"\n",
    "        'str' is a string.\n",
    "        Returns the string where the punctuations (if any) are removed\n",
    "        \"\"\"\n",
    "        for punctuation in string.punctuation:\n",
    "            str_ = str_.replace(punctuation, \"\")\n",
    "        return str_\n",
    "remove_punc_in_str('I ** am a person! How are you? hey^^')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['where', 'i?s', '3es!', 'a*ir', 'd2oy']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokens_to_lowercase(tokens):\n",
    "    \"\"\"\n",
    "    'tokens' is a list of tokens.\n",
    "    Returns a list of tokens where all the alphabets are converted to lowercase.\n",
    "    \"\"\"\n",
    "    return [token.lower() for token in tokens]\n",
    "tokens_to_lowercase(['Where', 'i?s', '3eS!', 'a*ir', 'd2oy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Where', 'i?s', '3eS!', 'a*ir', 'd2oy']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords(tokens, stopwords):\n",
    "    \"\"\"\n",
    "    'tokens' is a list of tokens. 'stopwords' is a set of stopwords (Use a set, not a list, for stopwords to make search faster)\n",
    "    Returns a list of tokens in which all the tokens that are stopwords\n",
    "    \"\"\"\n",
    "    return [token for token in tokens if token not in stopwords]\n",
    "\n",
    "remove_stopwords(['Where', 'i?s', '3eS!', 'a*ir', 'at', 'd2oy'], {\"at\", \"any\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the functions that we made, we preprocess the 'reviewText' feature in our dataframe. For the stop words, we use the stopwords provided by the nltk library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews_df['reviewText_processed'] = [remove_stopwords(tokens_to_lowercase(remove_tokens_with_num(nltk.word_tokenize(remove_punc_in_str(review)))), \\\n",
    "                                                          stopwords=stop_words) \\\n",
    "                                         for review in reviews_df['reviewText']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first five rows' preprocessed review text looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [charming, version, classic, dickens, tale, he...\n",
       "1    [good, emotionally, moving, christmas, carol, ...\n",
       "2    [dont, get, wrong, winkler, wonderful, charact...\n",
       "3    [henry, winkler, good, twist, classic, story, ...\n",
       "4    [one, best, scrooge, movies, henry, winkler, o...\n",
       "Name: reviewText_processed, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df['reviewText_processed'][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are not going to use the original review text anymore, let's delete it from our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews_df.drop(['reviewText'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our dataframe's first five rows look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>[charming, version, classic, dickens, tale, he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>[good, emotionally, moving, christmas, carol, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[dont, get, wrong, winkler, wonderful, charact...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>[henry, winkler, good, twist, classic, story, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[one, best, scrooge, movies, henry, winkler, o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall                               reviewText_processed\n",
       "0        4  [charming, version, classic, dickens, tale, he...\n",
       "1        3  [good, emotionally, moving, christmas, carol, ...\n",
       "2        3  [dont, get, wrong, winkler, wonderful, charact...\n",
       "3        5  [henry, winkler, good, twist, classic, story, ...\n",
       "4        4  [one, best, scrooge, movies, henry, winkler, o..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Save this Pandas dataframe as a pickle file (so that we don't have to load it again later)\n",
    "#reviews_df.to_pickle('preprocessed_reviews_df.pickle')\n",
    "\n",
    "# Load the dataframe that has been already saved as a pickle file\n",
    "reviews_df = pd.read_pickle('preprocessed_reviews_df.pickle')\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's split the dataset as the training set, validation set, and the test set. We will use 1018519 datapoints for the training set (around 60% of the entire 1697533), 339506 for the validation set (around 20% of the entire 1697533), and the test set will consist of the remaining 339508 datapoints.\n",
    "\n",
    "- All the fitting will be done via the training set.\n",
    "- Hyperparameter tuning and model selection (performance evaluation) will be done via the validation set. (Note: We could instead do k-fold cross validation, but since we have reasonably many datapoints in the validation set and also to reduce computational time, we use the train-validation-test approach)\n",
    "- The final model's accuracy will be evaluated via the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = reviews_df.shape[0]\n",
    "num_train = 1018519\n",
    "num_valid = 339506\n",
    "np.random.seed(0)\n",
    "indices_permutation = np.random.permutation(n)\n",
    "train_ind = indices_permutation[0:num_train]\n",
    "valid_ind = indices_permutation[num_train:num_train+num_valid]\n",
    "test_ind = indices_permutation[num_train+num_valid:]\n",
    "train_df = reviews_df.iloc[train_ind]\n",
    "valid_df = reviews_df.iloc[valid_ind]\n",
    "test_df = reviews_df.iloc[test_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save these dataframes for future use\n",
    "#train_df.to_pickle('train_df.pickle')\n",
    "#valid_df.to_pickle('valid_df.pickle')\n",
    "#test_df.to_pickle('test_df.pickle')\n",
    "\n",
    "# load the already-saved dataframes\n",
    "train_df = pd.read_pickle('train_df.pickle')\n",
    "valid_df = pd.read_pickle('valid_df.pickle')\n",
    "test_df = pd.read_pickle('test_df.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of rows and the number of columns for the three datasets are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1018519, 2), (339506, 2), (339508, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, valid_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Training Data - Rating Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's observe the frequency distribution of the rating scores in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings Frequency Distribution:  Counter({5: 543793, 4: 229244, 3: 120992, 1: 62876, 2: 61614})\n",
      "Percentage of training instances with 1-star rating: 6.173277081723561 %\n",
      "Percentage of training instances with 2-star rating: 6.0493716857515665 %\n",
      "Percentage of training instances with 3-star rating: 11.879208929828506 %\n",
      "Percentage of training instances with 4-star rating: 22.50758208732483 %\n",
      "Percentage of training instances with 5-star rating: 53.39056021537153 %\n"
     ]
    }
   ],
   "source": [
    "rating_freq_dict = Counter(train_df['overall'])\n",
    "print(\"Ratings Frequency Distribution: \", rating_freq_dict)\n",
    "# and the coresponding percentage\n",
    "num_train_instances = train_df.shape[0]\n",
    "for rate in [1,2,3,4,5]:\n",
    "   print(\"Percentage of training instances with %d-star rating:\" %rate, (rating_freq_dict[rate]/num_train_instances)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x209b6755b70>,\n",
       "  <matplotlib.axis.XTick at 0x209b6728e48>,\n",
       "  <matplotlib.axis.XTick at 0x209b674a8d0>,\n",
       "  <matplotlib.axis.XTick at 0x209b68a9128>,\n",
       "  <matplotlib.axis.XTick at 0x209b68a9b38>],\n",
       " <a list of 5 Text xticklabel objects>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAF5CAYAAACIpbAsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzt3X24XXV95/33BxAoCEFFEqzQYmljfDY8hdsh1MEbqqLV\ncUY5SgWUWi0gE1vG6i0lBdsiDoZLQMebh6I8TRmsoxVKFLGiQGFAqlBCWhWJqIkcxUCDITx854+1\nDm62Sc45+5xknwXv13XtK+z1++61vntvJR9+67fWTlUhSZLUZVsMuwFJkqSpMtBIkqTOM9BIkqTO\nM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOmxGBJslzklyYZDTJg0m+\nlWR+X83JSX7Ujn85yZ5949skObvdxwNJLk+yS1/NM5JcnGR1kvuSnJtk+76a3ZJckWRNkpVJTkuy\nRV/NS5Jcm+QXSe5OcsJ0fyaSJGnihh5okuwEXAc8BBwCzAP+BLivp+b9wLHAu4B9gTXA0iRb9+zq\nDOC1wJuAhcBzgM/2He6Sdv8HtbULgU/1HGcL4EpgK2ABcARwJHByT80OwFLgLmA+cAKwOMnRA38I\nkiRpSjLsH6dMciqwf1UduJGaHwEfraol7fMdgVXAEVV1Wfv8XuCwqvpcWzMXWAYsqKqbkswD/gXY\nq6pubWsOAa4AnltVK5O8GvgCsGtVjbY1fwScCjy7qh5J8h7gFGBOVT3S1vw18PtV9YJp/ngkSdIE\nDH2GBngdcHOSy5KsSvLN3tmOJHsAc4CvjG2rqvuBG4H9201708yq9NYsB1b01CwA7hsLM62rgQL2\n66m5bSzMtJYCs4AX9tRcOxZmemrmJpk12TcvSZKmbiYEmucB7wGWAwcDnwQ+nuQP2vE5NKFjVd/r\nVrVjALOBdW3Q2VDNHOAnvYNV9Sjws76a9R2HSdZIkqTNaKthN0ATqm6qqhPb599K8iLg3cCFw2tr\n+iR5Fs36oO8Da4fbjSRJnbIt8JvA0qr66YaKZkKg+THNWpdey4D/1P7zSiA0szC9MyOzgVt7arZO\nsmPfLM3sdmyspv+qpy2BZ/bV7NPXy+yesbE/Z49T0+8Q4OINjEmSpPG9jebinvWaCYHmOmBu37a5\nwN0AVXVXkpU0VyZ9Gx5fFLwfcHZbfwvwSFvTuyh4d+CGtuYGYKckL+9ZR3MQTVi6safmg0l27llH\nczCwGrijp+bDSbZsT1mN1SyvqtUbeI/fB7jooouYN2/euB/IVCxatIglS5Zs0mNoMH43M5ffzczm\n9zNzbY7vZtmyZRx++OHQ/l26ITMh0CwBrkvyAeAymqByNPCHPTVnAB9K8h2aN3QKcA/weWgWCSc5\nD/hYkvuAB4CPA9dV1U1tzZ1JlgLntFcqbQ2cCVxaVWMzK1+iCS4XtpeK79oe66yqerituQT4c+D8\nJB8BXgy8Fzh+I+9xLcC8efOYP3/+RsqmbtasWZv8GBqM383M5Xczs/n9zFyb+bvZ6JKNoQeaqro5\nyRtpLo0+keb+LsdX1f/sqTktyXY094zZCfg68OqqWtezq0XAo8DlwDbAVcAxfYd7K3AWzdVNj7W1\njweRqnosyaE0C5Ovp7nfzQXAST019yc5mGZ26GZgFFhcVedN7ZOQJEmDGnqgAaiqK2luaLexmsXA\n4o2MPwQc1z42VPNz4PBxjvMD4NBxam4HNnjfHEmStHnNhMu2JUmSpsRA8yQzMjIy7Ba0AX43M5ff\nzczm9zNzzaTvZug/ffBU0P7Q5i233HKLC9skSZqEb37zm+y1117Q/HTRNzdU5wyNJEnqPAONJEnq\nPAONJEnqPAONJEnqPAONJEnqPAONJEnqPAONJEnqPAONJEnqPAONJEnqPAONJEnqPAONJEnqPAON\nJEnqPAONJEnqPAONJEnqPAONJEnqPAONJEnqPAONJEnqPAONJEnqPAONJEnqPAONJEnqvK2G3YAk\nSZpeK1asYHR0dNhtTItly5ZNqM5AI0nSk8iKFSuYO3cea9c+OOxWNisDjSRJTyKjo6NtmLkImDfs\ndqbBlcCJ41YZaCRJelKaB8wfdhPTYGKnnFwULEmSOs9AI0mSOs9AI0mSOs9AI0mSOs9AI0mSOs9A\nI0mSOs9AI0mSOs9AI0mSOs9AI0mSOs9AI0mSOs9AI0mSOs9AI0mSOs9AI0mSOs9AI0mSOm/ogSbJ\nSUke63vc0VdzcpIfJXkwyZeT7Nk3vk2Ss5OMJnkgyeVJdumreUaSi5OsTnJfknOTbN9Xs1uSK5Ks\nSbIyyWlJtuireUmSa5P8IsndSU6Y7s9EkiRNztADTet2YDYwp338h7GBJO8HjgXeBewLrAGWJtm6\n5/VnAK8F3gQsBJ4DfLbvGJcA84CD2tqFwKd6jrMFcCWwFbAAOAI4Eji5p2YHYClwFzAfOAFYnOTo\nKbx3SZI0RVsNu4HWI1V17wbGjgdOqaovAiR5O7AKeANwWZIdgXcAh1XV19qao4BlSfatqpuSzAMO\nAfaqqlvbmuOAK5L8aVWtbMefD7yyqkaB25KcCJyaZHFVPQIcDjwNeGf7fFmSlwPvA86d/o9FkiRN\nxEyZofntJD9M8t0kFyXZDSDJHjQzNl8ZK6yq+4Ebgf3bTXvTBLPemuXAip6aBcB9Y2GmdTVQwH49\nNbe1YWbMUmAW8MKemmvbMNNbMzfJrIHeuSRJmrKZEGj+iebUziHAu4E9gGvb9S1zaELHqr7XrGrH\noDlVta4NOhuqmQP8pHewqh4FftZXs77jMMkaSZK0mQ39lFNVLe15enuSm4C7gTcDdw6nq01j0aJF\nzJr1xImckZERRkZGhtSRJEkzyaXto9c9E3rl0ANNv6paneRfgT2BfwRCMwvTOzMyGxg7fbQS2DrJ\njn2zNLPbsbGa/quetgSe2VezT187s3vGxv6cPU7NBi1ZsoT58+ePVyZJ0lPUSPvodTHNEtaNmwmn\nnJ4gydNpwsyPquoumqBwUM/4jjTrXq5vN90CPNJXMxfYHbih3XQDsFO7gHfMQTRh6caemhcn2bmn\n5mBgNXBHT83CNgz11iyvqtUDvWFJkjRlQw80ST6aZGGS30jy/wCfAx4G/mdbcgbwoSSvS/Ji4DM0\n80+fh8cXCZ8HfCzJ7ybZCzgfuK6qbmpr7qRZvHtOkn2SvAI4E7i0vcIJ4Es0weXC9l4zhwCnAGdV\n1cNtzSXAOuD8JC9I8hbgvcDpm+rzkSRJ45sJp5yeSxMUngXcC3wDWFBVPwWoqtOSbEdzz5idgK8D\nr66qdT37WAQ8ClwObANcBRzTd5y3AmfRXN30WFt7/NhgVT2W5FDgkzSzP2uAC4CTemruT3IwcDZw\nMzAKLK6q86b8KUiSpIENPdBU1bgrYqtqMbB4I+MPAce1jw3V/JxxTsJV1Q+AQ8epuR04cGM1kiRp\n8xr6KSdJkqSpMtBIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTO\nM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BI\nkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTO\nM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BI\nkqTOM9BIkqTOM9BIkqTOm3GBJsmfJXksycf6tp+c5EdJHkzy5SR79o1vk+TsJKNJHkhyeZJd+mqe\nkeTiJKuT3Jfk3CTb99XsluSKJGuSrExyWpIt+mpekuTaJL9IcneSE6b7c5AkSRM3owJNkn2AdwHf\n6tv+fuDYdmxfYA2wNMnWPWVnAK8F3gQsBJ4DfLbvEJcA84CD2tqFwKd6jrMFcCWwFbAAOAI4Eji5\np2YHYClwFzAfOAFYnOTogd+4JEmakhkTaJI8HbgIOBr4ed/w8cApVfXFqrodeDtNYHlD+9odgXcA\ni6rqa1V1K3AU8Iok+7Y184BDgHdW1c1VdT1wHHBYkjntcQ4Bng+8rapuq6qlwInAMUm2amsOB57W\n7mdZVV0GfBx433R/JpIkaWJmTKABzgb+vqqu6d2YZA9gDvCVsW1VdT9wI7B/u2lvmlmV3prlwIqe\nmgXAfW3YGXM1UMB+PTW3VdVoT81SYBbwwp6aa6vqkb6auUlmTeYNS5Kk6TEjAk2Sw4CXAR9Yz/Ac\nmtCxqm/7qnYMYDawrg06G6qZA/ykd7CqHgV+1lezvuMwyRpJkrQZbTV+yaaV5Lk0619eVVUPD7sf\nSZLUPUMPNMBewLOBbyZJu21LYGGSY2nWtIRmFqZ3ZmQ2MHb6aCWwdZId+2ZpZrdjYzX9Vz1tCTyz\nr2afvv5m94yN/Tl7nJr1WrRoEbNmPfGs1MjICCMjIxt7mSRJTxGXto9e90zolTMh0FwNvLhv2wXA\nMuDUqvpekpU0VyZ9Gx5fBLwfzbobgFuAR9qaz7U1c4HdgRvamhuAnZK8vGcdzUE0YenGnpoPJtm5\nZx3NwcBq4I6emg8n2bI9ZTVWs7yqVm/sjS5ZsoT58+eP83FIkvRUNdI+el1Mcz3Oxg090FTVGn4Z\nFgBIsgb4aVUtazedAXwoyXeA7wOn0ES2z7f7uD/JecDHktwHPEBz5dF1VXVTW3NnkqXAOUneA2wN\nnAlcWlVjMytfanu5sL1UfNf2WGf1nA67BPhz4PwkH6EJY++luRJLkiQNwdADzQbUE55UnZZkO5p7\nxuwEfB14dVWt6ylbBDwKXA5sA1wFHNO337cCZ9HMCj3W1j4eRKrqsSSHAp8Erqe5380FwEk9Nfcn\nOZhmduhmYBRYXFXnTe0tS5KkQc3IQFNV/3E92xYDizfymodo7itz3EZqfs4481ZV9QPg0HFqbgcO\n3FiNJEnafGbEZduSJElTYaCRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmd\nZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdN1CgSfIHSbad7mYkSZIGMegMzRJgZZJPJdl3\nOhuSJEmarEEDzXOAPwSeC1yX5PYkf5Lk2dPXmiRJ0sQMFGiqal1V/a+qei2wO3Ah8E7gniR/l+S1\nSTKdjUqSJG3IlBcFV9WPgauBrwIF7A1cCvxbkgOmun9JkqTxDBxokuyc5L8m+RZwHbAL8AbgN4Bf\nB/438Jlp6VKSJGkjthrkRUk+B7wGuAs4F/h0Vd3bU/JAktOA9029RUmSpI0bKNAA9wOvqqqvb6Tm\nXuC3B9y/JEnShA0UaKrqiAnUFPDdQfYvSZI0GYPeWG9JkmPWs/2YJKdPvS1JkqSJG3RR8H8Brl/P\n9n8C3jJ4O5IkSZM3aKDZmWYdTb/V7ZgkSdJmM2ig+S5wyHq2H0Jz5ZMkSdJmM+hVTmcAZyR5FnBN\nu+0g4L8BfzodjUmSJE3UoFc5ndP+2vYHgb9oN98DvLeqzp+u5iRJkiZi0BkaqupM4MwkuwK/qKqf\nT19bkiRJEzdwoBnT/paTJEnS0Ax6H5pnJ/mbJCuSrE2yrvcx3U1KkiRtzKAzNBcAvwV8FPgxza9s\nS5IkDcWggWYhsLCqbp3OZiRJkgYx6H1o7sFZGUmSNEMMGmgWAX+d5LnT2YwkSdIgBj3ldCGwA3B3\nkvuBh3sHq2qXqTYmSZI0UYMGmj+b1i4kSZKmYNA7BZ833Y1IkiQNatA1NCT5zSSLk1yYZJd228FJ\n5k1fe5IkSeMb9MZ6BwD/AhwIvBl4eju0F3Dy9LQmSZI0MYPO0HwEWFxVrwR67wz8FWDBlLuSJEma\nhEEDzUuAy9ez/SfAsyezoyTvTvKtJKvbx/VJfq+v5uQkP0ryYJIvJ9mzb3ybJGcnGU3yQJLLx06D\n9dQ8I8nF7THuS3Juku37anZLckWSNUlWJjktyRZ9NS9Jcm2SXyS5O8kJk3m/kiRp+g0aaFYDc9az\n/aXADye5rx8A7wfm05yyugb4/NhanCTvB44F3gXsC6wBlibZumcfZwCvBd5Ecxfj5wCf7TvOJcA8\n4KC2diHwqbHBNrhcSbNQegFwBHAkPafQkuwALAXuavs9AVic5OhJvmdJkjSNBg00fwucmuTZtHcM\nTrIfcDpw0WR2VFVXVNVVVfXdqvpOVX0I+Hd+eerqeOCUqvpiVd0OvJ0msLyhPe6OwDuARVX1tfbn\nGI4CXpFk37ZmHnAI8M6qurmqrgeOAw5LMhbMDgGeD7ytqm6rqqXAicAxScauBjsceFq7n2VVdRnw\nceB9k3nPkiRpeg0aaD4AfA/4Ec2C4DuA64H/A5wyaDNJtkhyGLAdcH2SPWhmgr4yVlNV9wM3Avu3\nm/ammVXprVkOrOipWQDc1/fbU1fThLH9empuq6rRnpqlwCzghT0111bVI301c5PMGuhNS5KkKRv0\nPjQPAUclORl4MU2o+WZV3TnI/pK8CLgB2BZ4AHhjVS1Psj9N6FjV95JV/PKU12xgXRt0NlQzh2Z9\nT+97eDTJz/pq1necsbFvtX9+byM1qzfyNiVJ0iYy6J2CAaiqu2jWk0zVnTTrb2YB/xn4TJKF07Bf\nSZL0FDBQoEny/29svKreNZn9tadwxmY+bm3XvhwPnAaEZhamd/ZkNjB2+mglsHWSHftmaWa3Y2M1\n/Vc9bQk8s69mn77WZveMjf05e5yaDVq0aBGzZj3xzNTIyAgjIyPjvVSSpKeAS9tHr3sm9MpBZ2h2\n7Xv+NJp1JjsA1w64z15bANtU1V1JVtJcmfRteHwR8H7A2W3tLcAjbc3n2pq5wO40p7Fo/9wpyct7\n1tEcRBOWbuyp+WCSnXvW0RxMcxrpjp6aDyfZsqoe7alZXlXjnm5asmQJ8+fPn8THIEnSU8lI++h1\nMc01ORs36Bqa1/Vva68E+h/88i//CUnyV8A/0Czi3QF4G80diA9uS84APpTkO8D3aRYd3wN8vu3l\n/iTnAR9Lch/NGpyPA9dV1U1tzZ1JlgLnJHkPsDVwJnBpVY3NrHyp7f3C9lLxXdtjnVVVY78mfgnw\n58D5ST5Cs37ovTSzSZIkaUimtIamV1U9kuSjwD8CH5vES3cBPk0TIFbTzMQcXFXXtPs9Lcl2NPeM\n2Qn4OvDqquq9Q/Ei4FGam/1tA1wFHNN3nLcCZ9Fc3fRYW/t4EKmqx5IcCnyS5oqtNcAFwEk9Nfcn\nOZhmduhmYJTmjsn+WKckSUM0bYGmtQfN6acJq6pxb0pXVYuBxRsZf4jmvjLHbaTm54wzZ1VVPwAO\nHafmdpoZJEmSNEMMuij4tP5NNDMsr2eSN9aTJEmaqkFnaPbve/4YcC/wZ8A5U+pIkiRpkgZdFHzA\ndDciSZI0qEF/+kCSJGnGGHQNzf+h/VHK8VTVvoMcQ5IkaaIGXUPzVeCPgH/llzevWwDMpbm8+qGp\ntyZJkjQxgwaanYCzq+qDvRuT/CUweyKXYkuSJE2XQdfQvBn4m/VsvwD4LwN3I0mSNIBBA81DNKeY\n+i3A002SJGkzG/SU08eBTyV5OXBTu20/4A+Bv56OxiRJkiZq0PvQ/GWSu2h+C2lsvcwy4F1Vdcl0\nNSdJkjQRA/+WUxtcDC+SJGnoBr6xXpIdkxyZ5OQkz2i3vTTJrtPXniRJ0vgGvbHei4CrgQeB3Wiu\nbroPeAvw68AR09SfJEnSuAadoVlCc7rpt4C1PduvABZOtSlJkqTJGDTQ7AN8oqr6f/7gh4CnnCRJ\n0mY1aKB5GHj6erbvCYwO3o4kSdLkDRpo/h44McnYGpxK8uvAqcDfTUtnkiRJEzRooPkT4JnASuDX\ngGuA79Gsp/ngRl4nSZI07Qa9sd59wCuTHAi8lOb00zeBpetZVyNJkrRJTTrQJHka8EXg2Kr6GvC1\nae9KkiRpEiZ9yqmqHgb2ApyJkSRJM8Kga2guBo6azkYkSZIGNehvORVwbJJXATcDa54wWPXfptqY\nJEnSRA0aaPYCvt3+80v6xjwVJUmSNqtJBZokzwPuqqoDNlE/kiRJkzbZNTT/Bjx77EmSv00ye3pb\nkiRJmpzJBpr0PX8NsP009SJJkjSQQa9ykiRJmjEmG2iKX1306yJgSZI0VJO9yinABUkeap9vC/yP\nJP2Xbf+n6WhOkjRzrVixgtHR0WG3MS123nlndt9992G3oSmYbKD5dN/zi6arEUlSd6xYsYK5c+ex\ndu2Dw25lWmy77XYsX77MUNNhkwo0VeXdgSVJjI6OtmHmImDesNuZomWsXXs4o6OjBpoOG/TGepIk\n0YSZ+cNuQvIqJ0mS1H0GGkmS1HkGGkmS1HkGGkmS1HkGGkmS1HkGGkmS1HkGGkmS1HlDDzRJPpDk\npiT3J1mV5HNJfmc9dScn+VGSB5N8OcmefePbJDk7yWiSB5JcnmSXvppnJLk4yeok9yU5N8n2fTW7\nJbkiyZokK5OclmSLvpqXJLk2yS+S3J3khOn8TCRJ0uQMPdAABwBnAvsBrwKeBnwpya+NFSR5P3As\n8C5gX2ANsDTJ1j37OQN4LfAmYCHwHOCzfce6hOYuUAe1tQuBT/UcZwvgSpobDi4AjgCOBE7uqdkB\nWArcRXM3qROAxUmOHvwjkCRJUzH0OwVX1Wt6nyc5EvgJsBfwjXbz8cApVfXFtubtwCrgDcBlSXYE\n3gEcVlVfa2uOApYl2beqbkoyDzgE2Kuqbm1rjgOuSPKnVbWyHX8+8MqqGgVuS3IicGqSxVX1CHA4\nTeh6Z/t8WZKXA+8Dzt0Un5EkSdq4mTBD028noICfASTZA5gDfGWsoKruB24E9m837U0TznprlgMr\nemoWAPeNhZnW1e2x9uupua0NM2OWArOAF/bUXNuGmd6auUlmDfB+JUnSFM2oQJMkNKeOvlFVd7Sb\n59CEjlV95avaMYDZwLo26GyoZg7NzM/jqupRmuDUW7O+4zDJGkmStBkN/ZRTn08ALwBeMexGNoVF\nixYxa9YTJ3FGRkYYGRkZUkeSJM0kl7aPXvdM6JUzJtAkOQt4DXBAVf24Z2glEJpZmN6ZkdnArT01\nWyfZsW+WZnY7NlbTf9XTlsAz+2r26Wttds/Y2J+zx6lZryVLljB/vr9KK0nS+o20j14X0yxf3bgZ\nccqpDTO/T7MYd0XvWFXdRRMUDuqp35Fm3cv17aZbgEf6auYCuwM3tJtuAHZqF/COOYgmLN3YU/Pi\nJDv31BwMrAbu6KlZ2Iah3prlVbV6Em9bkiRNk6EHmiSfAN4GvBVYk2R2+9i2p+wM4ENJXpfkxcBn\naOagPg+PLxI+D/hYkt9NshdwPnBdVd3U1txJs3j3nCT7JHkFzeXil7ZXOAF8iSa4XNjea+YQ4BTg\nrKp6uK25BFgHnJ/kBUneArwXOH1TfD6SJGl8M+GU07tpFv3+Y9/2o2iCC1V1WpLtaO4ZsxPwdeDV\nVbWup34R8ChwObANcBVwTN8+3wqcRXN102Nt7fFjg1X1WJJDgU/SzP6sAS4ATuqpuT/JwcDZwM3A\nKLC4qs4b6N1LkqQpG3qgqaoJzRJV1WJg8UbGHwKOax8bqvk545yIq6ofAIeOU3M7cODGaiRJ0uYz\n9FNOkiRJU2WgkSRJnWegkSRJnWegkSRJnWegkSRJnWegkSRJnWegkSRJnWegkSRJnWegkSRJnWeg\nkSRJnWegkSRJnWegkSRJnWegkSRJnWegkSRJnWegkSRJnWegkSRJnWegkSRJnWegkSRJnWegkSRJ\nnWegkSRJnWegkSRJnWegkSRJnWegkSRJnWegkSRJnWegkSRJnWegkSRJnWegkSRJnWegkSRJnWeg\nkSRJnWegkSRJnWegkSRJnWegkSRJnWegkSRJnWegkSRJnbfVsBuQpA1ZsWIFo6Ojw25j2uy8887s\nvvvuw25DelIy0EiakVasWMHcufNYu/bBYbcybbbddjuWL19mqJE2AQONpBlpdHS0DTMXAfOG3c40\nWMbatYczOjpqoJE2AQONpBluHjB/2E1ImuFcFCxJkjrPQCNJkjpvRgSaJAck+UKSHyZ5LMnr11Nz\ncpIfJXkwyZeT7Nk3vk2Ss5OMJnkgyeVJdumreUaSi5OsTnJfknOTbN9Xs1uSK5KsSbIyyWlJtuir\neUmSa5P8IsndSU6Yzs9DkiRNzowINMD2wD8DfwxU/2CS9wPHAu8C9gXWAEuTbN1TdgbwWuBNwELg\nOcBn+3Z1Cc0J+YPa2oXAp3qOswVwJc3aogXAEcCRwMk9NTsAS4G7aE7snwAsTnL0IG9ckiRN3YxY\nFFxVVwFXASTJekqOB06pqi+2NW8HVgFvAC5LsiPwDuCwqvpaW3MUsCzJvlV1U5J5wCHAXlV1a1tz\nHHBFkj+tqpXt+POBV1bVKHBbkhOBU5MsrqpHgMOBpwHvbJ8vS/Jy4H3AuZvg45EkSeOYKTM0G5Rk\nD2AO8JWxbVV1P3AjsH+7aW+acNZbsxxY0VOzALhvLMy0rqaZEdqvp+a2NsyMWQrMAl7YU3NtG2Z6\na+YmmTXg25QkSVMw4wMNTZgpmhmZXqvaMYDZwLo26GyoZg7wk97BqnoU+FlfzfqOwyRrJEnSZtSF\nQCNJkrRRM2INzThWAqGZhemdGZkN3NpTs3WSHftmaWa3Y2M1/Vc9bQk8s69mn77jz+4ZG/tz9jg1\n67Vo0SJmzXriWamRkRFGRkY29jJJkp4iLm0fve6Z0CtnfKCpqruSrKS5MunbAO0i4P2As9uyW4BH\n2prPtTVzgd2BG9qaG4Cdkry8Zx3NQTRh6caemg8m2blnHc3BwGrgjp6aDyfZsj1lNVazvKpWb+y9\nLFmyhPnzveOpJEnrN9I+el1Mcz3Oxs2IU05Jtk/y0iQvazc9r32+W/v8DOBDSV6X5MXAZ2gi2+fh\n8UXC5wEfS/K7SfYCzgeuq6qb2po7aRbvnpNknySvAM4ELm2vcAL4Ek1wubC918whwCnAWVX1cFtz\nCbAOOD/JC5K8BXgvcPqm+XQkSdJ4ZsoMzd7AV2kW/xa/DAefBt5RVacl2Y7mnjE7AV8HXl1V63r2\nsQh4FLg2U9J8AAAJHElEQVQc2IbmMvBj+o7zVuAsmqubHmtrjx8brKrHkhwKfBK4nuZ+NxcAJ/XU\n3J/kYJrZoZuBUWBxVZ03tY9AkiQNakYEmvbeMRudLaqqxcDijYw/BBzXPjZU83PGmbeqqh8Ah45T\ncztw4MZqJEnS5jMjTjlJkiRNhYFGkiR1noFGkiR1noFGkiR1noFGkiR1noFGkiR1noFGkiR1noFG\nkiR1noFGkiR1noFGkiR1noFGkiR1noFGkiR1noFGkiR13oz4te2nimXLlg27hWmx8847s/vuuw+7\nDUmSHmeg2YwOP/zwYbcwLbbddjuWL1/2pAk1K1asYHR0dNhtTBsDp6SnIgPNZnUK8JphNzFFy1i7\n9nBGR0efFH9prlixgrlz57F27YPDbmXaPNkCpyRNhIFms9oDmD/sJtRjdHS0DTMXAfOG3c40eHIF\nTkmaKAONBDRhxrApSV3lVU6SJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnz\nDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSS\nJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDQDSnJMkruS/CLJPyXZZ9g9\nNS4ddgPaIL+bmcvvZmbz+5m5Zs53Y6AZQJK3AKcDJwEvB74FLE2y81AbA2bS/7jUz+9m5vK7mdn8\nfmaumfPdGGgGswj4VFV9pqruBN4NPAi8Y7htSZL01GSgmaQkTwP2Ar4ytq2qCrga2H9YfUmS9FRm\noJm8nYEtgVV921cBczZ/O5IkaathN/AUsW3zx3Wb4VD3ABdvwv3fBcCyZcs24TE2n1++jyuBTf2e\nNvV3A0+m78fvZmZ7cn0/fjeD2xz/33n8785tN1aV5myJJqo95fQg8Kaq+kLP9guAWVX1xvW85q1s\n+m9ckqQns7dV1SUbGnSGZpKq6uEktwAHAV8ASJL2+cc38LKlwNuA7wNrN0ObkiQ9WWwL/CbN36Ub\n5AzNAJK8GbiA5uqmm2iuevrPwPOr6t4htiZJ0lOSMzQDqKrL2nvOnAzMBv4ZOMQwI0nScDhDI0mS\nOs/LtiVJUucZaCRJUucZaJ4EkhyQ5AtJfpjksSSvH3ZPgiQfSHJTkvuTrEryuSS/M+y+1Ejy7iTf\nSrK6fVyf5PeG3Zd+VZI/a//d9rFh9yJIclL7ffQ+7hh2XwaaJ4ftaRYm/zHgoqiZ4wDgTGA/4FXA\n04AvJfm1oXalMT8A3g/Mp/k5k2uAzyeZN9Su9ARJ9gHeRfMjwJo5bqe5KGZO+/gPw23Hq5yeFKrq\nKuAqePyeOJoBquo1vc+THAn8hOYvz28Moyf9UlVd0bfpQ0neAyxg099eVROQ5OnARcDRwIlDbkdP\n9MhMu7LXGRpp89mJZgbtZ8NuRE+UZIskhwHbATcMux897mzg76vqmmE3ol/x2+0yh+8muSjJbsNu\nyBkaaTNoZ87OAL5RVUM/16xGkhfRBJhtgQeAN1bVncPtSgBtwHwZsPewe9Gv+CfgSGA5sCuwGLg2\nyYuqas2wmjLQSJvHJ4AXAK8YdiN6gjuBlwKzaO72/ZkkCw01w5XkuTT/AfCqqnp42P3oiaqq9ycI\nbk9yE3A38Gbgb4bTlYFG2uSSnAW8Bjigqn487H70S1X1CPC99umtSfYFjgfeM7yuRLPO7NnAN3vW\nBW4JLExyLLBNeVfYGaOqVif5V2DPYfZhoJE2oTbM/D5wYFWtGHY/GtcWwDbDbkJcDby4b9sFNIu1\nTzXMzCzt4u09gc8Msw8DzZNAku1p/sc09l8yz0vyUuBnVfWD4XX21JbkE8AI8HpgTZLZ7dDqqvJX\n14csyV8B/wCsAHYA3gYcCBw8zL4E7TqMJ6w1S7IG+GlVeQXakCX5KPD3NKeZfh34C+Bh4NJh9mWg\neXLYG/gqzRU0BZzebv808I5hNSXeTfN9/GPf9qMY8n/JCIBdaP4/siuwGvg2cLBX1MxYzsrMHM8F\nLgGeBdxLcxuKBVX102E25Y9TSpKkzvM+NJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMMNJIk\nqfMMNJIkqfMMNJIkqfMMNJIkqfMMNJLUSvJYktcPuw9Jk2egkdQpSf6mDR6PJlmX5HtJPpJkwr+S\nneSkJLeuZ2gOzQ9WSuoYf5xSUhf9A3AksDWwF82PfT4GfGAS+/iVH7Krqp9MR3OSNj9naCR10UNV\ndW9V/bCqvgB8Gfh/xwaTnJpkeZI1Sb6b5OQkW7ZjRwAnAS/tmel5ezv2+CmnJL/RPn9jkmvaff1z\nkgW9jST5wyQrkvx7ksuS/Nck922uD0JSw0AjqdOSvAh4BbCuZ/P9wNuBecB7gaOBRe3Y3wKnA/8C\nzAZ2bbdtyIeB04CXAv8KXJJki/bYrwA+CSwBXgZcA/x/rGf2R9Km5SknSV30uiQP0Pw7bBvgUeCP\nxwar6q96alckOR14C/Dfq2ptkn8HHqmqeydwrI9W1VXQrL0Bbgf2pAk3xwJXVtWStvY7bch57dTe\nnqTJMtBI6qJrgHcDT6eZeXmkqv732GCStwDHAb/V1mwFrB7wWLf1/POPgQC70ASaucDf9dXfhIFG\n2uw85SSpi9ZU1V1VdRvwTmBBkqMAkuwPXAR8kSZYvAz4S5oFxIN4uOefx04l+e9OaYZxhkZSp1VV\nJfkr4PQklwD7A9+vqlPHapL8Zt/L1gFbTmT344wvB/bp27bvBPYraZr5XxmSngz+F81l28cC/wbs\nnuQtSZ6X5L3AG/rqvw/skeSlSZ6VZEOzNxnnuGcCr0myKMmeSf4I+D1cFCxtdgYaSZ1XVY8CZwEn\nAFcDZ9CEjVuBBcDJfS/5LHAV8FXgJ8BhY7vq3/X6Dtdz3Otp1vIsAv4ZOJjmiqe1g78bSYNIlf8h\nIUnTJck5wO9U1YHD7kV6KnENjSRNQZI/obmx3xrgNcAfAO8ZalPSU5AzNJI0BUn+FjgQ2AH4HvDx\nqjpnuF1JTz0GGkmS1HkuCpYkSZ1noJEkSZ1noJEkSZ1noJEkSZ1noJEkSZ1noJEkSZ1noJEkSZ1n\noJEkSZ33fwHVdiJjVSImsQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x209b6724fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar([1,2,3,4,5], [rating_freq_dict[rate] for rate in [1,2,3,4,5]], width=0.5)\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xticks([1.25,2.25,3.25,4.25,5.25], [1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the ratings 4 and 5 are much more frequent compared to the other ratings, let's downsample those labels. Let's (randomly) maintain just the 30% of the 5-star ratings (maintain 163137 observations and remove 380656 observations), and also let's (randomly) maintain just the 60% of the 4-star ratings (maintain 137546 observations and remove 91698 observations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 5-star ratings\n",
    "rating5_rows = train_df.index[train_df['overall']==5].tolist()\n",
    "np.random.seed(0)\n",
    "rating5_rows_perm = np.random.permutation(rating5_rows)\n",
    "rows_to_delete = rating5_rows_perm[0:380656]\n",
    "train_df.drop(rows_to_delete, inplace=True)\n",
    "# 4-star ratings\n",
    "rating4_rows = train_df.index[train_df['overall']==4].tolist()\n",
    "np.random.seed(0)\n",
    "rating4_rows_perm = np.random.permutation(rating4_rows)\n",
    "rows_to_delete = rating4_rows_perm[0:91698]\n",
    "train_df.drop(rows_to_delete, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the dataframe for future use\n",
    "#train_df.to_pickle('train_balanced_df.pickle')\n",
    "\n",
    "# Load the already-saved dataframe\n",
    "train_df = pd.read_pickle('train_balanced_df.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now, the distribution of the ratings in the training set looks more balanced compared to the original training set (as shown below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x20931af5710>,\n",
       "  <matplotlib.axis.XTick at 0x20931af2be0>,\n",
       "  <matplotlib.axis.XTick at 0x20931af5908>,\n",
       "  <matplotlib.axis.XTick at 0x20931a9b390>,\n",
       "  <matplotlib.axis.XTick at 0x20931a9bda0>],\n",
       " <a list of 5 Text xticklabel objects>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAF5CAYAAACIpbAsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20931b0e8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rating_freq_dict = Counter(train_df['overall'])\n",
    "plt.bar([1,2,3,4,5], [rating_freq_dict[rate] for rate in [1,2,3,4,5]], width=0.5)\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xticks([1.25,2.25,3.25,4.25,5.25], [1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of rows and the number of columns for the training set are now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(546165, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will try several feature designs of the training dataset. In particular, we will focus on bag-of-words (BOW) representations, in which we represent the training set as a matrix where each row corresponds to each training instance, and each column represents each token, or vocabulary. Different versions of the BOW feature design depends on the different ways to select the tokens to include (as columns). Then, each row $i$ & column $j$ entry of the feature matrix is the number of times the token in column $j$ appears in the review text in row $i$. Moreover, since most of the entries of the feature matrix will be 0, to deal with memory error issues, we use scipy sparse matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Design 1: Top 3000 Collection Term Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, what makes the feature design different is based on how we choose the tokens to include in our feature matrix. In this \"top 3000 collection term frequency\" design, we choose the top 3000 tokens, where the ranking is based on how many times the token appeared throughout the whole training set (that is: across all the 546165 review texts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movie',\n",
       " 'film',\n",
       " 'one',\n",
       " 'like',\n",
       " 'good',\n",
       " 'great',\n",
       " 'would',\n",
       " 'story',\n",
       " 'really',\n",
       " 'time']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_freq_dict = Counter([token for list_tokens in train_df['reviewText_processed'] for token in list_tokens])\n",
    "\n",
    "# list of top 3000 tokens based on collection term frequency\n",
    "top3000_CTF_tokens = [token_and_count[0] for token_and_count in token_freq_dict.most_common(3000)]\n",
    "# first ten\n",
    "top3000_CTF_tokens[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Top 3000 CTF - Feature matrix\n",
    "#X_sparse_top3000_CTF = sparse.vstack([sparse.csr_matrix([np.sum(np.array(list_tokens)==token) for token in top3000_CTF_tokens]) \\\n",
    "#                                      for list_tokens in train_df['reviewText_processed']])\n",
    "\n",
    "# Save X_sparse_top3000_CTF as a file, so we can load it again later instead of doing preprocessing again\n",
    "#sparse.save_npz('X_sparse_top3000_CTF.npz', X_sparse_top3000_CTF)\n",
    "\n",
    "# Load it\n",
    "X_sparse_top3000_CTF = sparse.load_npz('X_sparse_top3000_CTF.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Design 2: Top 3000 Document Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, we choose the top 3000 tokens, where the ranking is based on the number of training instances such that the token appears at least once in the training instance's review text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movie',\n",
       " 'one',\n",
       " 'like',\n",
       " 'good',\n",
       " 'film',\n",
       " 'great',\n",
       " 'would',\n",
       " 'time',\n",
       " 'story',\n",
       " 'really']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_tokens = np.array(list(token_freq_dict.keys()))\n",
    "each_token_df_dict = {unique_token:0 for unique_token in unique_tokens}\n",
    "\n",
    "for list_tokens in train_df['reviewText_processed']:\n",
    "    for token in np.unique(list_tokens):\n",
    "        each_token_df_dict[token] += 1\n",
    "\n",
    "top3000_DF_tokens = sorted(each_token_df_dict, key=each_token_df_dict.get)[::-1][0:3000]\n",
    "# first ten\n",
    "top3000_DF_tokens[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_sparse_top3000_DF = sparse.vstack([sparse.csr_matrix([np.sum(np.array(list_tokens)==token) for token in top3000_DF_tokens]) \\\n",
    "#                                      for list_tokens in train_df['reviewText_processed']])\n",
    "\n",
    "# Save X_sparse_top3000_CTF as a file, so we can load it again later instead of doing preprocessing again\n",
    "#sparse.save_npz('X_sparse_top3000_DF.npz', X_sparse_top3000_DF)\n",
    "\n",
    "# Load it\n",
    "X_sparse_top3000_DF = sparse.load_npz('X_sparse_top3000_DF.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Design 3: TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our last feature design is the tf-idf (term frequency–inverse document frequency) which combines term frequency (a local statistic that shows how many times a term appears in a document) and inverse document frequency (a global statistic that is inversely proportional to the number of times a term appears across the entire collection of documents). Some more information about the tf-idf weighing scheme can be found [here](http://www.tfidf.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2',\n",
       "        preprocessor=<function return_itself at 0x00000208BBBB9EA0>,\n",
       "        smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "        sublinear_tf=False, token_pattern=None,\n",
       "        tokenizer=<function return_itself at 0x00000208BBBB9EA0>,\n",
       "        use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def return_itself(text):\n",
    "    return text\n",
    "\n",
    "# Since we already did the tokenization, for the tokenizer and the preprocessor\n",
    "# in our tfidf obejct, we use a function that simply returns the input text.\n",
    "tfidf_vectorize = TfidfVectorizer(analyzer='word', tokenizer=return_itself, preprocessor=return_itself, token_pattern=None)\n",
    "\n",
    "# Learn the vocabulary and idf values from the training dataset.\n",
    "tfidf_vectorize.fit(train_df['reviewText_processed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Based on the learned vocabulary and idf values, compute the tf-idf feature matrix for the training set.\n",
    "#X_sparse_tfidf = tfidf_vectorize.transform(train_df['reviewText_processed'])\n",
    "\n",
    "# Save X_sparse_tfidf as a file, so we can load it again later instead of doing preprocessing again\n",
    "#sparse.save_npz('X_sparse_tfidf.npz', X_sparse_tfidf)\n",
    "\n",
    "# Load it\n",
    "X_sparse_tfidf = sparse.load_npz('X_sparse_tfidf.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Designs on Validation Set and Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the five feature designs, let's create the corresponding feature matrix for the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Validation set - Feature design 1: Top 3000 CTF\n",
    "#X_sparse_valid_top3000_CTF = sparse.vstack([sparse.csr_matrix([np.sum(np.array(list_tokens)==token) for token in top3000_CTF_tokens]) \\\n",
    "#                                            for list_tokens in valid_df['reviewText_processed']])\n",
    "\n",
    "# Save X_sparse_valid_top3000_CTF as a file, so we can load it again later instead of doing preprocessing again\n",
    "#sparse.save_npz('X_sparse_valid_top3000_CTF.npz', X_sparse_valid_top3000_CTF)\n",
    "\n",
    "# Load it\n",
    "X_sparse_valid_top3000_CTF = sparse.load_npz('X_sparse_valid_top3000_CTF.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Validation set - Feature design 2: Top 3000 DF\n",
    "#X_sparse_valid_top3000_DF = sparse.vstack([sparse.csr_matrix([np.sum(np.array(list_tokens)==token) for token in top3000_DF_tokens]) \\\n",
    "#                                           for list_tokens in valid_df['reviewText_processed']])\n",
    "\n",
    "# Save X_sparse_valid_top3000_DF as a file, so we can load it again later instead of doing preprocessing again\n",
    "#sparse.save_npz('X_sparse_valid_top3000_DF.npz', X_sparse_valid_top3000_DF)\n",
    "\n",
    "# Load it\n",
    "X_sparse_valid_top3000_DF = sparse.load_npz('X_sparse_valid_top3000_DF.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Validation set - Feature design 3: tf-idf\n",
    "#X_sparse_valid_tfidf = tfidf_vectorize.transform(valid_df['reviewText_processed'])\n",
    "\n",
    "# Save X_sparse_valid_tfidf as a file, so we can load it again later instead of doing preprocessing again\n",
    "#sparse.save_npz('X_sparse_valid_tfidf.npz', X_sparse_valid_tfidf)\n",
    "\n",
    "# Load it\n",
    "X_sparse_valid_tfidf = sparse.load_npz('X_sparse_valid_tfidf.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test set - Feature design 1: Top 3000 CTF\n",
    "#X_sparse_test_top3000_CTF = sparse.vstack([sparse.csr_matrix([np.sum(np.array(list_tokens)==token) for token in top3000_CTF_tokens]) \\\n",
    "#                                           for list_tokens in test_df['reviewText_processed']])\n",
    "\n",
    "# Save X_sparse_test_top3000_CTF as a file, so we can load it again later instead of doing preprocessing again\n",
    "#sparse.save_npz('X_sparse_test_top3000_CTF.npz', X_sparse_test_top3000_CTF)\n",
    "\n",
    "# Load it\n",
    "X_sparse_test_top3000_CTF = sparse.load_npz('X_sparse_test_top3000_CTF.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test set - Feature design 2: Top 3000 DF\n",
    "#X_sparse_test_top3000_DF = sparse.vstack([sparse.csr_matrix([np.sum(np.array(list_tokens)==token) for token in top3000_DF_tokens]) \\\n",
    "#                                          for list_tokens in test_df['reviewText_processed']])\n",
    "\n",
    "# Save X_sparse_test_top3000_DF as a file, so we can load it again later instead of doing preprocessing again\n",
    "#sparse.save_npz('X_sparse_test_top3000_DF.npz', X_sparse_test_top3000_DF)\n",
    "\n",
    "# Load it\n",
    "X_sparse_test_top3000_DF = sparse.load_npz('X_sparse_test_top3000_DF.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test set - Feature design 3: tf-idf\n",
    "#X_sparse_test_tfidf = tfidf_vectorize.transform(test_df['reviewText_processed'])\n",
    "\n",
    "# Save X_sparse_test_tfidf as a file, so we can load it again later instead of doing preprocessing again\n",
    "#sparse.save_npz('X_sparse_test_tfidf.npz', X_sparse_test_tfidf)\n",
    "\n",
    "# Load it\n",
    "X_sparse_test_tfidf = sparse.load_npz('X_sparse_test_tfidf.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the feature matrices, we begin training the model on the data.\n",
    "\n",
    "We use the following models:\n",
    "- Multinomial Naive Bayes\n",
    "- Logistic Regression\n",
    "- Linear Support Vector Machine (SVM)\n",
    "\n",
    "We will decide the best model (out of total 9 models: combinations across three designs and three model types) based on the validation set, and then evaluate the final test accuracy (via the test dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our error metric in model selection, we use the root mean squared error (RMSE), which is defined as:\n",
    "\n",
    "$\\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (true_{i} - pred_{i})^{2}}$ \n",
    "\n",
    "where:\n",
    "- $n$ denotes the number of datapoints (i.e. number of predictions)\n",
    "- $true_{i}$ denotes the true label of the $i^{th}$ datapoint; for $i \\in \\{ 1, \\cdots, n \\}$\n",
    "- $pred_{i}$ denotes the predicted label of the $i^{th}$ datapoint; for $i \\in \\{ 1, \\cdots, n \\}$\n",
    "\n",
    "Of course, we could instead use other common metrics such as prediction accuracy, mean absolute error (MAE), etc. But we choose RMSE because:\n",
    "\n",
    "- This task's labels are essentially numerical, so e.g. predicting a true label 3 as 2 is not as bad as predicting a true label 5 as 2. So accuracy might not be a good metric.\n",
    "- With the similiar reason, since we want to penalize larger errors (i.e. difference between the true rating score and the predicted rating score) more, RMSE could be better than MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function that computes the RMSE, given the true labels and the predicted labels\n",
    "def rmse(trueY, predictedY):\n",
    "    return math.sqrt(mean_squared_error(trueY, predictedY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we consider a Multinomial Naive Bayes classifier, where we assume:\n",
    "\n",
    "- Each feature (here, each token) is conditionally independent given the label (just like any Naive Bayes)\n",
    "- Each feature has a Multinomial distribution, where the event probabilities are defined for each label. That is: For each label $c$, there is a set of probabilities that sum to 1 ($p_{1}^{(c)}, p_{2}^{(c)}, \\cdots, p_{m}^{(c)}$ where $m$ denotes the number of features). This is why we call it the \"Multinomial\" Naive Bayes.\n",
    "\n",
    "We need to choose the value of 'alpha', which is a hyperparameter representing the strength of the additive smoothing, which is a method of reducing the influence of rare words throughout the documents. The options are from 0 to 1 (So 'alpha'=0 means no smothing at all), and we decide the best value via the performance on the validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Design 1: Top 3000 Collection Term Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha= 0.2  RMSE= 1.2180286572283823\n",
      "alpha= 0.5  RMSE= 1.2180431664362785\n",
      "alpha= 0.8  RMSE= 1.217962154480632\n",
      "alpha= 1  RMSE= 1.2178944388610145\n"
     ]
    }
   ],
   "source": [
    "alphas = [0.2, 0.5, 0.8, 1]\n",
    "\n",
    "for alpha in alphas:\n",
    "    # train the model with this alpha\n",
    "    nb_clf1 = MultinomialNB(alpha=alpha).fit(X_sparse_top3000_CTF, train_df['overall'])\n",
    "    # predict on validation set\n",
    "    preds = nb_clf1.predict(X_sparse_valid_top3000_CTF)\n",
    "    # compute RMSE\n",
    "    print(\"alpha=\", alpha, \" RMSE=\", rmse(trueY=valid_df['overall'], predictedY=preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Design 2: Top 3000 Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha= 0.2  RMSE= 1.2045914783114997\n",
      "alpha= 0.5  RMSE= 1.2045230110222744\n",
      "alpha= 0.8  RMSE= 1.2045609130382573\n",
      "alpha= 1  RMSE= 1.204483885109605\n"
     ]
    }
   ],
   "source": [
    "for alpha in alphas:\n",
    "    # train the model with this alpha\n",
    "    nb_clf2 = MultinomialNB(alpha=alpha).fit(X_sparse_top3000_DF, train_df['overall'])\n",
    "    # predict on validation set\n",
    "    preds = nb_clf2.predict(X_sparse_valid_top3000_DF)\n",
    "    # compute RMSE\n",
    "    print(\"alpha=\", alpha, \" RMSE=\", rmse(trueY=valid_df['overall'], predictedY=preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Design 3: TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha= 0.2  RMSE= 1.0452000468671305\n",
      "alpha= 0.5  RMSE= 1.0803356774590935\n",
      "alpha= 0.8  RMSE= 1.1032842877898215\n",
      "alpha= 1  RMSE= 1.1139807142665923\n"
     ]
    }
   ],
   "source": [
    "for alpha in alphas:\n",
    "    # train the model with this alpha\n",
    "    nb_clf3 = MultinomialNB(alpha=alpha).fit(X_sparse_tfidf, train_df['overall'])\n",
    "    # predict on validation set\n",
    "    preds = nb_clf3.predict(X_sparse_valid_tfidf)\n",
    "    # compute RMSE\n",
    "    print(\"alpha=\", alpha, \" RMSE=\", rmse(trueY=valid_df['overall'], predictedY=preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Logistic Regression (L2-regularized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we consider the logistic regression model. Note that we're dealing with classification with more than two labels, so binary logistic regression cannot be directly used. There are several ways to deal with multiclass classification via logistic regression, and we use the 'one vs rest' (aka 'one vs all') approach. \n",
    "\n",
    "Recall the binary logistic regression model: There are two possible labels $0$ and $1$, and the model says that the probability that a datapoint with features $x = [x_{1}, x_{2}, \\cdots, x_{m}]$ has label $1$ is: $P(Y=1 | X=x) = \\frac{\\text{exp} \\{ \\beta_{0} + \\beta_{1} x_{1} + \\cdots + \\beta_{m} x_{m} \\}}{1 + \\text{exp} \\{ \\beta_{0} + \\beta_{1} x_{1} + \\cdots + \\beta_{m} x_{m} \\} }$, and the probability that it has label $0$ is:  $P(Y=0 | X=x) = 1 - P(Y=1 | X=x)$.\n",
    "\n",
    "Let $q$ denote the number of possible labels (so $q>2$). In the 'one vs rest' approach, we build one binary logistic regression model for each of the $q$ labels. For each $j \\in \\{1, \\cdots, q\\}$, the $j^{th}$ binary logistic regression model treats the label value $j$ as 'success' (i.e. Y=1), and all the other labels (i.e. all values in $\\{ 1, \\cdots, j-1, j+1, \\cdots, q$) as 'failure' (i.e. Y=0). We train each of the $q$-many binary logistic regression models (so total $q$-many sets of parameters are fitted). Then, when making prediction for an arbitrary datapoint, we do:\n",
    "\n",
    "- For each $j \\in \\{ 1, \\cdots, q \\}$, we compute the fitted probability of that datapoint having label $j$ via the $j^{th}$ binary logistic regression formula.\n",
    "- Then, our prediction is the label $j$ that has the highest fitted probability.\n",
    "\n",
    "Moreover, to prevent overfitting, we will apply L2-regularization. There is a hyperparameter 'C' which is the inverse of the strength of regularization (so smaller value means stronger regularization). As before, we will assess validation performance to choose our 'C'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Design 1: Top 3000 Collection Term Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C= 0.25  RMSE= 1.0305175904727957\n",
      "C= 0.5  RMSE= 1.0305604630273788\n",
      "C= 1.0  RMSE= 1.0307233624713912\n",
      "C= 1.25  RMSE= 1.030763368923047\n"
     ]
    }
   ],
   "source": [
    "Cs = [0.25, 0.5, 1.0, 1.25]\n",
    "\n",
    "for C in Cs:\n",
    "    # train the model with this C\n",
    "    lr_clf1 = LogisticRegression(penalty='l2', C=C).fit(X_sparse_top3000_CTF, train_df['overall'])\n",
    "    # predict on validation set\n",
    "    preds = lr_clf1.predict(X_sparse_valid_top3000_CTF)\n",
    "    # compute RMSE\n",
    "    print(\"C=\", C, \" RMSE=\", rmse(trueY=valid_df['overall'], predictedY=preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Design 2: Top 3000 Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C= 0.25  RMSE= 1.0229857841542933\n",
      "C= 0.5  RMSE= 1.0232276145595993\n",
      "C= 1.0  RMSE= 1.0233269212057456\n",
      "C= 1.25  RMSE= 1.0233226037258707\n"
     ]
    }
   ],
   "source": [
    "for C in Cs:\n",
    "    # train the model with this C\n",
    "    lr_clf2 = LogisticRegression(penalty='l2', C=C).fit(X_sparse_top3000_DF, train_df['overall'])\n",
    "    # predict on validation set\n",
    "    preds = lr_clf2.predict(X_sparse_valid_top3000_DF)\n",
    "    # compute RMSE\n",
    "    print(\"C=\", C, \" RMSE=\", rmse(trueY=valid_df['overall'], predictedY=preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Design 3: TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C= 0.25  RMSE= 0.9508953610117883\n",
      "C= 0.5  RMSE= 0.9478626593688789\n",
      "C= 1.0  RMSE= 0.9490117272716462\n",
      "C= 1.25  RMSE= 0.9501423556267181\n"
     ]
    }
   ],
   "source": [
    "for C in Cs:\n",
    "    # train the model with this C\n",
    "    lr_clf3 = LogisticRegression(penalty='l2', C=C).fit(X_sparse_tfidf, train_df['overall'])\n",
    "    # predict on validation set\n",
    "    preds = lr_clf3.predict(X_sparse_valid_tfidf)\n",
    "    # compute RMSE\n",
    "    print(\"C=\", C, \" RMSE=\", rmse(trueY=valid_df['overall'], predictedY=preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Linear SVM (L2-regularized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we consider the linear SVM model. Note that we can use nonlinear SVM via kernels, but we won't do so here. Again, we're dealing with a multiclass classification task, so binary SVM can't be directly used. As in logistic regression, we use the 'one vs rest' approach, where each label has its own binary linear SVM classifier that treats itself as one class and all other labels as the other class.\n",
    "\n",
    "Recall the binary linear SVM model: It has two labels, and its goal is to learn the hyperplane (dimension depends on number of features) that has the maximum margin. This is done by minimizing the hinge loss. Here, we have a hyperparameter 'C' which represents the penalty to the error terms (i.e. how severely will we penalize misclassification of training data). So smaller value of this hyperparameter can prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Design 1: Top 3000 Collection Term Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C= 0.25  RMSE= 1.1884688051807504\n",
      "C= 0.5  RMSE= 1.150737811363019\n",
      "C= 1  RMSE= 1.1772483387164265\n",
      "C= 1.25  RMSE= 1.1300935581472134\n"
     ]
    }
   ],
   "source": [
    "Cs = [0.25, 0.5, 1, 1.25]\n",
    "\n",
    "for C in Cs:\n",
    "    # train the model with this C\n",
    "    svm_clf1 = LinearSVC(penalty='l2', loss='hinge', C=C).fit(X_sparse_top3000_CTF, train_df['overall'])\n",
    "    # predict on validation set\n",
    "    preds = svm_clf1.predict(X_sparse_valid_top3000_CTF)\n",
    "    # compute RMSE\n",
    "    print(\"C=\", C, \" RMSE=\", rmse(trueY=valid_df['overall'], predictedY=preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Design 2: Top 3000 Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C= 0.25  RMSE= 1.1503960508175202\n",
      "C= 0.5  RMSE= 1.1438922123228141\n",
      "C= 1  RMSE= 1.1594167627728131\n",
      "C= 1.25  RMSE= 1.1418136331346997\n"
     ]
    }
   ],
   "source": [
    "for C in Cs:\n",
    "    # train the model with this C\n",
    "    svm_clf2 = LinearSVC(penalty='l2', loss='hinge', C=C).fit(X_sparse_top3000_DF, train_df['overall'])\n",
    "    # predict on validation set\n",
    "    preds = svm_clf2.predict(X_sparse_valid_top3000_DF)\n",
    "    # compute RMSE\n",
    "    print(\"C=\", C, \" RMSE=\", rmse(trueY=valid_df['overall'], predictedY=preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Design 3: TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C= 0.25  RMSE= 1.0267851286246052\n",
      "C= 0.5  RMSE= 1.0203261969482234\n",
      "C= 1  RMSE= 1.0161621820484101\n",
      "C= 1.25  RMSE= 1.0162549332781925\n"
     ]
    }
   ],
   "source": [
    "for C in Cs:\n",
    "    # train the model with this C\n",
    "    svm_clf3 = LinearSVC(penalty='l2', loss='hinge', C=C).fit(X_sparse_tfidf, train_df['overall'])\n",
    "    # predict on validation set\n",
    "    preds = svm_clf3.predict(X_sparse_valid_tfidf)\n",
    "    # compute RMSE\n",
    "    print(\"C=\", C, \" RMSE=\", rmse(trueY=valid_df['overall'], predictedY=preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the results.\n",
    "\n",
    "For feature design 1 (Top 3000 Collection Term Frequency):\n",
    "- The Naive Bayes model's best 'alpha' is 1 (with RMSE 1.218)\n",
    "- The logistic regression model's best 'C' is 0.25 (with RMSE 1.031)\n",
    "- The SVM model's best 'C' is 1.25 (with RMSE 1.13)\n",
    "\n",
    "For feature design 2 (Top 3000 Document Frequency):\n",
    "- The Naive Bayes model's best 'alpha' is 1 (with RMSE 1.204)\n",
    "- The logistic regression model's best 'C' is 0.25 (with RMSE 1.023)\n",
    "- The SVM model's best 'C' is 1.25 (with RMSE 1.142)\n",
    "\n",
    "For feature design 3 (TF-IDF):\n",
    "- The Naive Bayes model's best 'alpha' is 0.2 (with RMSE 1.045)\n",
    "- The logistic regression model's best 'C' is 0.5 (with RMSE 0.948)\n",
    "- The SVM model's best 'C' is 1.25 (with RMSE 1.016)\n",
    "\n",
    "Overall, we can see that the TF-IDF feature design yields lower RMSE (which is better) compared to the other feature designs, and in regards to models, it seems the logistic regression model tends to yield lower RMSE compared to others. We choose the logistic regression model with 'C' = 0.5 with the TF-IDF feature design as our final model.\n",
    "\n",
    "But note that we do not know about the uncertainty of those RMSE values, and we can use the bootstrap to estimate the uncertainty, which will let us determine whether those differences in RMSE values are meaningful (that is: not negligably small)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Test Set Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will fit the logistic regression model with 'C' = 0.5 with the TF-IDF design. Note that here, we will use both the training set and the validation set (combined into one dataset) to train the final model, and then assess the performance on test dataset prediction.\n",
    "\n",
    "Also, for the performance metric, we will use MAE which gives us the exact 'distance' of the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Combine training set and validation set\n",
    "X_sparse_combined_tfidf = sparse.vstack((X_sparse_tfidf, X_sparse_valid_tfidf))\n",
    "\n",
    "# Corresponding labels\n",
    "true_labels_combined = train_df['overall'].append(valid_df['overall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE= 0.502718639914\n"
     ]
    }
   ],
   "source": [
    "# train the model with this C=0.5\n",
    "lr_clf_final = LogisticRegression(penalty='l2', C=0.5).fit(X_sparse_combined_tfidf, true_labels_combined)\n",
    "# predict on test set\n",
    "preds = lr_clf_final.predict(X_sparse_test_tfidf)\n",
    "# compute MAE\n",
    "print(\"MAE=\", mean_absolute_error(test_df['overall'], preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final model yields MAE of 0.503, which means that on average, the difference between the true rating and the predicted rating is near 0.5. Considering the fact that the ratings are integers from 1 to 5, this final test MAE is pretty good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's examine two extreme examples (one very positive review and one very negative review) on how our final predicts the rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 1], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# positive\n",
    "sentence1 = \"This is very good. I love it, and I will watch it again.\"\n",
    "# negative\n",
    "sentence2 = \"Horrible film. You won't like it. It is extremely bad.\"\n",
    "\n",
    "extremes = pd.DataFrame({'reviewText':[sentence1, sentence2]})\n",
    "extremes['reviewText_processed'] = [remove_stopwords(tokens_to_lowercase(remove_tokens_with_num(nltk.word_tokenize(remove_punc_in_str(review)))), \\\n",
    "                                                          stopwords=stop_words) \\\n",
    "                                         for review in extremes['reviewText']]\n",
    "extremes.drop(['reviewText'], axis=1, inplace=True)\n",
    "\n",
    "tfidf_extremes = tfidf_vectorize.transform(extremes['reviewText_processed'])\n",
    "\n",
    "# predict\n",
    "lr_clf_final.predict(tfidf_extremes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final model predicts the positive sentence as rating 5 and the negative sentence as rating 1, as desired."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
